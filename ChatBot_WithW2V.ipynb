{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AGNozDPc-u71"
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "\n",
    "_, _, filenames = next(walk('./data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfVlRd57bl7Q",
    "outputId": "e65eadf5-9cc5-4eda-cbdd-9a8de9084b6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5855\n",
      "5855\n",
      "['Bạn thuê trọ bao nhiêu tiền', 'Nhà bạn có bao nhiêu người vậy ']\n",
      "['Mình thuê khoảng 3 tr một tháng', 'Nhà mình có 7 người']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for fname in filenames:\n",
    "    f = open('./data/' + fname,'r')\n",
    "    sentences = f.readlines()\n",
    "    for sent in sentences:\n",
    "        q_a = sent.split('__eou__')\n",
    "        for i in range(len(q_a)):\n",
    "            q_a[i] = re.sub('^ | $','',q_a[i])\n",
    "        try:\n",
    "            questions.append(q_a[0])\n",
    "            answers.append(q_a[1])\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "# remove punctuation\n",
    "questions = [re.sub(r'[^\\w\\s]','',sent) for sent in questions]\n",
    "            \n",
    "print(len(questions))\n",
    "print(len(answers))\n",
    "print(questions[:2])\n",
    "print(answers[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4Y1yDJr_yXW",
    "outputId": "55d726c1-0207-4980-e2e6-858d1594396c"
   },
   "outputs": [],
   "source": [
    "import vncorenlp\n",
    "\n",
    "annotator = vncorenlp.VnCoreNLP(\"VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYvJE19jepc5",
    "outputId": "e4ed7939-c659-4013-82e8-cdef1ed2fde6"
   },
   "outputs": [],
   "source": [
    "questions_tokenized = []\n",
    "\n",
    "for sent in questions:\n",
    "    questions_tokenized.extend(annotator.tokenize(sent.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_tokenized = []\n",
    "\n",
    "for sent in answers:\n",
    "    answers_tokenized.extend(annotator.tokenize(sent.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc1uTA6uDQCQ"
   },
   "source": [
    "#Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Q_gCwzN1Dylj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 231486\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "# pretrained_w2v = KeyedVectors.load_word2vec_format(\"./PretrainW2V/wiki.vi.model.bin.gz\", binary=True)\n",
    "\n",
    "# print(\"Vocab size: \" + str(len(pretrained_w2v.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 2928\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(sentences=questions_tokenized+answers_tokenized,\n",
    "                     size=50, window=5, sg=1, min_count=2)\n",
    "\n",
    "print(\"Vocab size: \" + str(len(w2v_model.wv.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sum_vector(list_of_vector, length=50):\n",
    "    sum = np.zeros(length)\n",
    "    for vec in list_of_vector:\n",
    "        sum = sum + vec\n",
    "\n",
    "    return sum\n",
    "\n",
    "def concat_vector(list_of_vector):\n",
    "    return np.concatenate(list_of_vector, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_vectorized = []\n",
    "\n",
    "for i,sent in enumerate(questions_tokenized):\n",
    "    sent_vectorized = []\n",
    "    for word in sent:\n",
    "        try:\n",
    "            sent_vectorized.append(w2v_model.wv[word])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    questions_vectorized.append(sum_vector(sent_vectorized))\n",
    "    \n",
    "corpus = questions_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    total = 0\n",
    "    for i in range(len(x)):\n",
    "        total += math.pow(x[i]-y[i],2)\n",
    "        \n",
    "    return math.sqrt(total)\n",
    "\n",
    "def cosine_similarity(v1,v2):\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)\n",
    "\n",
    "def get_best_index_byEuclidDistance(question, corpus=corpus):\n",
    "    min_d = math.inf\n",
    "    best_index = 0\n",
    "    \n",
    "    for i,sent in enumerate(corpus):\n",
    "        d = euclidean_distance(question, corpus[i])\n",
    "        if d < min_d:\n",
    "            min_d = d\n",
    "            best_index = i\n",
    "    \n",
    "    return best_index\n",
    "\n",
    "def get_best_index_byCosineSimilarity(question, corpus=corpus):\n",
    "    max_cosine = -(math.inf)\n",
    "    best_index = 0\n",
    "    \n",
    "    for i,sent in enumerate(corpus):\n",
    "        cosine = cosine_similarity(question, corpus[i])\n",
    "        if cosine > max_cosine:\n",
    "            max_cosine = cosine\n",
    "            best_index = i\n",
    "    \n",
    "    return best_index\n",
    "\n",
    "def get_answer_byEuclidDistance(question):\n",
    "    question = re.sub(r'[^\\w\\s]','',question)\n",
    "    \n",
    "    question_tokenized = annotator.tokenize(question.lower())[-1]\n",
    "    \n",
    "    question_vectorized = []\n",
    "    for word in question_tokenized:\n",
    "        try:\n",
    "            question_vectorized.append(w2v_model.wv[word])\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    question_vectorized = sum_vector(question_vectorized)\n",
    "    \n",
    "    best_index = get_best_index_byEuclidDistance(question_vectorized)\n",
    "    \n",
    "    return answers[best_index]\n",
    "\n",
    "def get_answer_byCosineSimilarity(question):\n",
    "    question = re.sub(r'[^\\w\\s]','',question)\n",
    "    \n",
    "    question_tokenized = annotator.tokenize(question.lower())[-1]\n",
    "    \n",
    "    question_vectorized = []\n",
    "    for word in question_tokenized:\n",
    "        try:\n",
    "            question_vectorized.append(w2v_model.wv[word])\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    question_vectorized = sum_vector(question_vectorized)\n",
    "    \n",
    "    best_index = get_best_index_byCosineSimilarity(question_vectorized)\n",
    "    \n",
    "    return answers[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.944911182523068"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([1,2,1,1],[1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer by euclid distance: mình có người yêu rồi\n",
      "Answer by cosine similarity: công ty mình môi trường chuyên nghiệp\n"
     ]
    }
   ],
   "source": [
    "question = \"chào bạn, cho mình làm quen nhé\"\n",
    "\n",
    "print(\"Answer by euclid distance: \" + get_answer_byEuclidDistance(question))\n",
    "print(\"Answer by cosine similarity: \" + get_answer_byCosineSimilarity(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer by euclid distance: Okay luôn nhá\n",
      "Answer by cosine similarity: Yêu chứ, yêu cả đất nước này luôn cơ\n"
     ]
    }
   ],
   "source": [
    "question = \"mình yêu bạn, làm người yêu mình nhé\"\n",
    "\n",
    "print(\"Answer by euclid distance: \" + get_answer_byEuclidDistance(question))\n",
    "print(\"Answer by cosine similarity: \" + get_answer_byCosineSimilarity(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-chatbot",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
